{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment4.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunny-5555/Computer-Vision-Assignments/blob/update-assignment/a4-cnn/Assignment4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS7T20gWaEkg"
      },
      "source": [
        "# Machine Vision - Assignment 4: Image Classification with Convolutional Neural Networks\n",
        "\n",
        "---\n",
        "\n",
        "Prof. Dr. Markus Enzweiler, Esslingen University of Applied Sciences\n",
        "\n",
        "markus.enzweiler@hs-esslingen.de\n",
        "\n",
        "---\n",
        "\n",
        "This is the fourth assignment for the \"Machine Vision\" lecture. \n",
        "It covers:\n",
        "* training a deep CNN from scratch on [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
        "* evaluating the effects of different optimizers and regularization\n",
        "* finetuning an existing CNN on [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
        "\n",
        "**Make sure that \"GPU\" is selected in Runtime -> Change runtime type**\n",
        "\n",
        "To successfully complete this assignment, it is assumed that you already have some experience in Python and numpy. You can either use [Google Colab](https://colab.research.google.com/) for free with a private (dedicated) Google account (recommended) or a local Jupyter installation.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RH3vu3HiqaZS"
      },
      "source": [
        "## Preparations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFz0s31SxNyP"
      },
      "source": [
        "### Import important libraries (you should probably start with these lines all the time ...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPcN62DgZ6Gg"
      },
      "source": [
        "# OpenCV\n",
        "import cv2   \n",
        "\n",
        "# NumPy                    \n",
        "import numpy as np   \n",
        "\n",
        "# Python stuff\n",
        "import glob, urllib, os, requests\n",
        "\n",
        "# Matplotlib    \n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "# make sure we show all plots directly below each cell\n",
        "%matplotlib inline \n",
        "\n",
        "# Some Colab specific packages\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "  # image display\n",
        "  from google.colab.patches import cv2_imshow \n",
        "\n",
        "# Tensorflow and Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization, Activation, Input, Lambda\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Check the GPU that we got from Colab\n",
        "!nvidia-smi \n",
        "device_name = tf.test.gpu_device_name()\n",
        "print(\"Device used for TensorFlow : {}\".format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANRNsyDPTm9x"
      },
      "source": [
        "\n",
        "### Some helper functions that we will need"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQ5AIQr1TsHU"
      },
      "source": [
        "def my_imshow(image, windowTitle=\"Image\"):\n",
        "  '''\n",
        "  Displays an image and differentiates between Google Colab and a local Python installation. \n",
        "\n",
        "  Args: \n",
        "    image: The image to be displayed\n",
        "\n",
        "  Returns:\n",
        "    - \n",
        "  '''\n",
        "\n",
        "  if 'google.colab' in str(get_ipython()):\n",
        "    cv2_imshow(image)\n",
        "  else:\n",
        "    cv2.imshow(windowTitle, image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQJnwTJQPzvF"
      },
      "source": [
        "## Exercise 1 - Define and train a (small) CNN on CIFAR-10 (10 points) \n",
        "\n",
        "In this exercise you will be defining and training a small deep CNN on CIFAR-10. We will build on the previous assignment, where a fully connected multilayer perceptron has been trained on CIFAR-10. Its performance on the validation dataset was approx. 53% which is not a stellar performance. The CNN will significantly improve performance over the multilayer perceptron.\n",
        "\n",
        "Additionally, the effect of different optimizers and regularization techniques will be evaluated step-by-step. \n",
        "\n",
        "We will be using TensorFlow and [Keras](https://keras.io/), a high-level API built on top of TensorFlow that provides an easier API to the training of neural networks in comparison to plain TensorFlow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFzeGgygOeX8"
      },
      "source": [
        "### Getting familiar with the CIFAR-10 dataset (**PROVIDED**)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXZ4tzXccZB9"
      },
      "source": [
        "# CIFAR-10 is available as standard dataset in Keras. Nice :)\n",
        "\n",
        "\n",
        "# load the data\n",
        "(trainSamples, _trainLabels), (testSamples, _testLabels) = cifar10.load_data()\n",
        "\n",
        "# scale the image data to float 0-1 (always recommended with neural networks)\n",
        "trainSamples = trainSamples.astype('float32') / 255.0 \n",
        "testSamples  = testSamples.astype('float32') / 255.0 \n",
        "\n",
        "# convert a class vector (integers) to binary class matrix.\n",
        "trainLabels  = to_categorical(_trainLabels)\n",
        "testLabels   = to_categorical(_testLabels)\n",
        "\n",
        "# text representation of class labels\n",
        "classNames = ['airplane', 'automobile', 'bird', \\\n",
        "               'cat', 'deer', 'dog', \\\n",
        "               'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# Visualize 25 random images\n",
        "plt.figure(figsize=(10,10))\n",
        "indices = np.arange(len(trainSamples))\n",
        "np.random.shuffle(indices)\n",
        "count=0\n",
        "for i in indices[0:25]:\n",
        "    plt.subplot(5,5,count+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(trainSamples[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(\"label: {}\".format(classNames[np.argmax(trainLabels[i])]))\n",
        "    count = count+1\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATTSTJH6P8ZX"
      },
      "source": [
        "### CNN Model Definition (**add your code here**)\n",
        "\n",
        "We want to design a standard \"feed-forward\" CNN. In Keras-terms, this is referred to as a [sequential model](https://www.tensorflow.org/guide/keras/sequential_model). The basic TensorFlow tutorial on [Convolutional Neural Networks](https://www.tensorflow.org/tutorials/images/cnn) is a good resource to learn how CNNs are defined and trained. \n",
        "\n",
        "We will need the following layers (input to output):\n",
        "* 1 [Input](https://www.tensorflow.org/api_docs/python/tf/keras/Input) layer with ```shape = (32,32,3)``` that inputs our 32x32x3 image into the CNN\n",
        "\n",
        "\n",
        "* 2 [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) convolutional layers with **32** filters of size 3x3, ```relu``` activation functions, ```he_uniform``` kernel initializers and ```same``` padding\n",
        "* 1 [MaxPool2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D) layer with 2x2 pooling\n",
        "\n",
        "* 2 [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) convolutional layers with **64** filters of size 3x3, ```relu``` activation functions, ```he_uniform``` kernel initializers and ```same``` padding\n",
        "* 1 [MaxPool2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D) layer with 2x2 pooling\n",
        "\n",
        "* 2 [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) convolutional layers with **128** filters of size 3x3, ```relu``` activation functions, ```he_uniform``` kernel initializers and ```same``` padding\n",
        "* 1 [MaxPool2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D) layer with 2x2 pooling\n",
        "\n",
        "\n",
        "* 1 [Flatten](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten) layer to flatten the input for the upcoming fully connected layer \n",
        "\n",
        "* 1 [Dense](https://keras.io/api/layers/core_layers/dense/) fully connected layer with 128 neurons and ```relu``` activation and  ```he_uniform``` kernel initializers\n",
        "\n",
        "* 1 [Dense](https://keras.io/api/layers/core_layers/dense/) fully connected output layer with 10 neurons (1 per class) and ```softmax``` activation. \n",
        "\n",
        "\n",
        "Your ```model.summary()``` should look as follows (layer indices might differ). Notice how the representation shrinks with each pooling layer.\n",
        "\n",
        "```_________________________________________________________________\n",
        "Model: \"sequential\"\n",
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
        "_________________________________________________________________\n",
        "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
        "_________________________________________________________________\n",
        "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
        "_________________________________________________________________\n",
        "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
        "_________________________________________________________________\n",
        "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
        "_________________________________________________________________\n",
        "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
        "_________________________________________________________________\n",
        "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
        "_________________________________________________________________\n",
        "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
        "_________________________________________________________________\n",
        "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
        "_________________________________________________________________\n",
        "flatten (Flatten)            (None, 2048)              0         \n",
        "_________________________________________________________________\n",
        "dense (Dense)                (None, 128)               262272    \n",
        "_________________________________________________________________\n",
        "dense_1 (Dense)              (None, 10)                1290      \n",
        "=================================================================\n",
        "Total params: 550,570\n",
        "Trainable params: 550,570\n",
        "Non-trainable params: 0\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrPJ4BVfQFIV"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Define the layers of the CNN model\n",
        "\n",
        "# input layer\n",
        "model.add(tf.keras.layers.InputLayer(input_shape=(32, 32, 3)))\n",
        "# 2 conv layers and 1 pooling layer \n",
        "# convolutional layers with 32 filters of size 3x3, relu activation functions, he_uniform kernel initializers and same padding\n",
        "# pooling layer with 2x2 pooling\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "# 2 conv layers and 1 pooling layer\n",
        "# convolutional layers with 64 filters of size 3x3, relu activation functions, he_uniform kernel initializers and same padding\n",
        "# pooling layer with 2x2 pooling\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "# 2 conv layers and 1 pooling layer\n",
        "# convolutional layers with 128 filters of size 3x3, relu activation functions, he_uniform kernel initializers and same padding\n",
        "# pooling layer with 2x2 pooling\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "# fully connected layer\n",
        "# layer to flatten the input for the upcoming fully connected layer\n",
        "# fully connected layer with 128 neurons and relu activation and he_uniform kernel initializers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=128, activation='relu', kernel_initializer='he_uniform'))\n",
        "# output layer\n",
        "# fully connected output layer with 10 neurons (1 per class) and softmax activation\n",
        "model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5P7r_rHQ9hm"
      },
      "source": [
        "### CNN training with different optimizers (**add your code here**)\n",
        "\n",
        "Compile the model ([model.compile()](https://keras.io/api/models/model_training_apis/)) and use ```categorical_crossentropy``` as loss and ```accuracy``` as metric (see previous assignment). \n",
        "\n",
        "\n",
        "Train your CNN using [model.fit()](https://keras.io/api/models/model_training_apis/). Pass ```trainSamples```and ```trainLabels```as training set and ```testSamples```and ```testLabels``` as ```validation_data```. \n",
        "\n",
        "Use the following hyper-parameters:\n",
        "* ```batch_size = 64```\n",
        "* ```epochs = 30``` \n",
        "* ```verbose = 1```\n",
        "\n",
        "Run the training three times and switch optimizers with each training run by passing different optimizers to [model.compile()](https://keras.io/api/models/model_training_apis/) (all other settings remain the same):\n",
        "* Stochastic Gradient Descent (plain): ```optimizer=SGD(learning_rate=3e-4)```\n",
        "* RMSprop (with momentum): ```optimizer=RMSprop(learning_rate=3e-4)```\n",
        "* Adam: ```optimizer=Adam(learning_rate=3e-4)```\n",
        "\n",
        "Different optimizers might need different numbers of training epochs (hyper parameter !!). To find a good number of training epochs for each optimizer, we can use [tf.keras.callbacks.EarlyStopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) to stop training automatically based on a performance metric that is evaluated during training. Browse through [tf.keras.callbacks.EarlyStopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) and add ```EarlyStopping``` as a callback to [model.fit()](https://keras.io/api/models/model_training_apis/) to stop training when ```val_loss```, the current loss on the test set, did not improve for 3 epochs.   \n",
        "\n",
        "The overall training should take between 7 to 15 seconds per epoch (**on a GPU**). Training times depend on the GPU that we have been assigned by Colab. Reported accuracies on the test data should be approx. 74% with the best optimizer variant. \n",
        "\n",
        "Compare the different results by computing the accuracy on the test set using:\n",
        "```\n",
        "# evaluate model\n",
        "_, acc = model.evaluate(testSamples, testLabels, verbose=1)\n",
        "print(\"Accuracy = {}\".format(acc))\n",
        "```\n",
        "\n",
        " **Which optimizer gave the best accuracy on the test set?**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsVNpyKvRAUC"
      },
      "source": [
        "# make deep copies of the original (initialized) model to make sure to always train from scratch\n",
        "modelSGD     = tf.keras.models.clone_model(model)\n",
        "modelRMS     = tf.keras.models.clone_model(model)\n",
        "modelAdam    = tf.keras.models.clone_model(model)\n",
        "\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "# Stochastic Gradient Descent (plain)\n",
        "modelSGD.compile(optimizer=SGD(learning_rate=3e-4),\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "history = modelSGD.fit(x=trainSamples, y=trainLabels, batch_size=64, epochs=30, verbose=1, callbacks=[callback], validation_data=(testSamples, testLabels))\n",
        "\n",
        "_, acc = modelSGD.evaluate(testSamples, testLabels, verbose=1)\n",
        "print(\"Accuracy = {}\".format(acc))\n",
        "\n",
        "# RMSprop (with momentum)\n",
        "modelRMS.compile(optimizer=RMSprop(learning_rate=3e-4),\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "history = modelRMS.fit(x=trainSamples, y=trainLabels, batch_size=64, epochs=30, verbose=1, callbacks=[callback], validation_data=(testSamples, testLabels))\n",
        "\n",
        "_, acc = modelRMS.evaluate(testSamples, testLabels, verbose=1)\n",
        "print(\"Accuracy = {}\".format(acc))\n",
        "\n",
        "# Adam\n",
        "modelAdam.compile(optimizer=Adam(learning_rate=3e-4),\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "history = modelAdam.fit(x=trainSamples, y=trainLabels, batch_size=64, epochs=30, verbose=1, callbacks=[callback], validation_data=(testSamples, testLabels))\n",
        "\n",
        "_, acc = modelAdam.evaluate(testSamples, testLabels, verbose=1)\n",
        "print(\"Accuracy = {}\".format(acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbxoU8sZA_we"
      },
      "source": [
        "### Adding regularization (**add your code here**)\n",
        "\n",
        "Now we add some regularization to our CNN in terms of [Dropout](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) layers with a ```rate``` of 0.33, i.e. 33% of the neurons will be randomly disabled in each batch.  \n",
        "\n",
        "Add a [Dropout](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) layer after every MaxPool2D layer in your model and retrain using the optimizer than performed best in the previous evaluation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anJBa9xFBzzw"
      },
      "source": [
        "modelDropOut = Sequential()\n",
        "\n",
        "# Define the layers of the CNN model with dropout\n",
        "# input layer\n",
        "modelDropOut.add(tf.keras.layers.InputLayer(input_shape=(32, 32, 3)))\n",
        "\n",
        "# 2 conv layers and 1 pooling layer \n",
        "# convolutional layers with 32 filters of size 3x3, relu activation functions, he_uniform kernel initializers and same padding\n",
        "modelDropOut.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu', kernel_initializer='he_uniform'))\n",
        "modelDropOut.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu', kernel_initializer='he_uniform'))\n",
        "# pooling layer with 2x2 pooling\n",
        "modelDropOut.add(MaxPool2D(pool_size=(2, 2)))\n",
        "# layers with a rate of 0.33, i.e. 33% of the neurons will be randomly disabled in each batch\n",
        "modelDropOut.add(Dropout(rate=0.33))\n",
        "\n",
        "# 2 conv layers and 1 pooling layer\n",
        "# convolutional layers with 64 filters of size 3x3, relu activation functions, he_uniform kernel initializers and same padding\n",
        "modelDropOut.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', kernel_initializer='he_uniform'))\n",
        "modelDropOut.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', kernel_initializer='he_uniform'))\n",
        "# pooling layer with 2x2 pooling\n",
        "modelDropOut.add(MaxPool2D(pool_size=(2, 2)))\n",
        "# layers with a rate of 0.33, i.e. 33% of the neurons will be randomly disabled in each batch\n",
        "modelDropOut.add(Dropout(rate=0.33))\n",
        "\n",
        "# 2 conv layers and 1 pooling layer\n",
        "# convolutional layers with 128 filters of size 3x3, relu activation functions, he_uniform kernel initializers and same padding\n",
        "modelDropOut.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu', kernel_initializer='he_uniform'))\n",
        "modelDropOut.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu', kernel_initializer='he_uniform'))\n",
        "# pooling layer with 2x2 pooling\n",
        "modelDropOut.add(MaxPool2D(pool_size=(2, 2)))\n",
        "# layers with a rate of 0.33, i.e. 33% of the neurons will be randomly disabled in each batch\n",
        "modelDropOut.add(Dropout(rate=0.33))\n",
        "\n",
        "# fully connected layer\n",
        "# layer to flatten the input for the upcoming fully connected layer\n",
        "# fully connected layer with 128 neurons and relu activation and he_uniform kernel initializers\n",
        "modelDropOut.add(Flatten())\n",
        "modelDropOut.add(Dense(units=128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\n",
        "# output layer\n",
        "# fully connected output layer with 10 neurons (1 per class) and softmax activation\n",
        "modelDropOut.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "# Model summary\n",
        "print(modelDropOut.summary())\n",
        "\n",
        "# train the CNN\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "modelDropOut.compile(optimizer=Adam(learning_rate=3e-4),\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "history = modelDropOut.fit(x=trainSamples, y=trainLabels, batch_size=64, epochs=30, verbose=1, callbacks=[callback], validation_data=(testSamples, testLabels))\n",
        "\n",
        "_, acc = modelDropOut.evaluate(testSamples, testLabels, verbose=1)\n",
        "print(\"Accuracy = {}\".format(acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuSs_vknCtkC"
      },
      "source": [
        "### Visualize some predictions (**PROVIDED**)\n",
        "\n",
        "Now we should have a model that can achieve approx. 80% accuracy on the test set. Let's look at some predictions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSY0FhF5C05u"
      },
      "source": [
        "def visualizePredictions(model, testSamples, testSamplesUnnormalized):\n",
        "\n",
        "  # select 50 images randomly from the test set and run them through the CNN\n",
        "  plt.figure(figsize=(20,10))\n",
        "\n",
        "  # 50 random images\n",
        "  indices = np.arange(len(testSamples))\n",
        "  np.random.shuffle(indices)\n",
        "  count=0\n",
        "  for i in indices[0:50]:\n",
        "      plt.subplot(5,10,count+1)\n",
        "      plt.xticks([])\n",
        "      plt.yticks([])\n",
        "      plt.grid(False)\n",
        "      plt.imshow(testSamplesUnnormalized[i], cmap=plt.cm.binary)\n",
        "\n",
        "      # predict MLP (need to reshape 32 x 32 x 3 pixels -> 1 x 3072 pixels)\n",
        "      prediction = model.predict(np.expand_dims(testSamples[i], axis=0))\n",
        "    \n",
        "      # visualize true and predicted labels\n",
        "      groundTruthLabel = classNames[np.argmax(testLabels[i])]\n",
        "      predictedLabel   = classNames[np.argmax(prediction)]\n",
        "      plt.xlabel(\"T: {} / P: {}\".format(groundTruthLabel, predictedLabel))\n",
        "      count = count+1\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq-3rRuAPZ_5"
      },
      "source": [
        "# visualize predictions of our current model\n",
        "visualizePredictions(modelDropOut, testSamples, testSamples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kdud_yCDpaT"
      },
      "source": [
        "### Visualize some more predictions (**PROVIDED**)\n",
        "\n",
        "That does look quite good on CIFAR-10's test set. Let's see how the model performs on some random images grabbed from Google. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vMKBQXrD0cU"
      },
      "source": [
        "import io\n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "# path to test images (you will have to modify that)\n",
        "testDir = \"/content/cnn/\"\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/sunny-5555/Computer-Vision-Assignments/main/a4-cnn/data.zip'\n",
        "\n",
        "response = requests.get(url, allow_redirects = True)\n",
        "stream = io.BytesIO(response.content)\n",
        "\n",
        "print(\"unzipping {}\".format(url))\n",
        "\n",
        "with zipfile.ZipFile(stream, 'r') as zip_ref:\n",
        "    zip_ref.extractall(testDir)\n",
        "\n",
        "\n",
        "# some helper functions to load images from a given path and run a prediction\n",
        "\n",
        "def myPredict(model, image):\n",
        "\n",
        "  # resize image to model dimensions\n",
        "  resizedImage = cv2.resize(image, (32,32))\n",
        "\n",
        "  # run prediction\n",
        "  x=np.expand_dims(resizedImage, axis=0)\n",
        "  x=x.astype('float32') / 255\n",
        "  predictedClasses = model.predict(x)\n",
        "  return predictedClasses\n",
        "\n",
        "\n",
        "def getArgMaxLabel(classNames, predictedClasses):\n",
        "  return classNames[np.argmax(predictedClasses)]\n",
        "\n",
        "\n",
        "def visualizePredictionsExtImages(model, predictionFunction):\n",
        "  # get all images in testDir\n",
        "  files = [testDir+f for f in os.listdir(testDir) if f.startswith(\"test\") and f.endswith(\".jpg\")]\n",
        "\n",
        "  for f in files: \n",
        "    plt.figure()  \n",
        "    # load image\n",
        "\n",
        "    testImage = cv2.imread(f)\n",
        "\n",
        "    # display image\n",
        "    plt.imshow(cv2.cvtColor(cv2.resize(testImage, (400,400)), cv2.COLOR_BGR2RGB))\n",
        "    plt.axis(\"off\")\n",
        "    plt.draw()\n",
        "    \n",
        "    # evaluate our CNN\n",
        "    predictedClasses = predictionFunction(model, testImage)\n",
        "    predictedLabel   = getArgMaxLabel(classNames, predictedClasses)\n",
        "    plt.title(\"{} with a probability of {:.3f}%\".format(predictedLabel, 100*np.max(predictedClasses)))\n",
        "    plt.draw()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xWZmY5sPnS9"
      },
      "source": [
        "# visualize predictions of our current model\n",
        "visualizePredictionsExtImages(modelDropOut)#, myPredict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SY_ni4U0HNGn"
      },
      "source": [
        "## Exercise 2 - Fine-tuning / transfer learning of a larger CNN on CIFAR-10 (10 points) \n",
        "\n",
        "In this exercise you will be [fine-tuning](https://www.tensorflow.org/tutorials/images/transfer_learning) a large CNN that has been trained on ImageNet to the CIFAR-10 dataset. As we have seen in the lecture, this involves replacing the output layer by (a set of) output layers that correspond to our problem. Here: 10 output neurons for the 10 classes of CIFAR-10. \n",
        "\n",
        "As a base CNN we will use [InceptionResNet-V2](https://keras.io/api/applications/inceptionresnetv2/). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R8YGKXeIFPh"
      },
      "source": [
        "### CNN model definition (**PROVIDED**)\n",
        "\n",
        "We will load a pre-trained InceptionResNet-V2 and replace its output layers by a new stack of fully connected layers. Luckily, common models that have been pre-trained on ImageNet are readily available in [keras.applications](https://keras.io/api/applications/). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wams4zAGIfw5"
      },
      "source": [
        "# 1) Load the base InceptionResNet-V2 that has been trained on imagenet\n",
        "\n",
        "# We can omit the original ImageNet output layer directly while loading the model. \n",
        "# Additionally, we need to upscale our 32,32 to the input that InceptionResNet-V2 requires (160,160,3)\n",
        "\n",
        "# We will link different parts of our model together:\n",
        "# input -> upscale(input) -> base_model(upscale) -> base_model.output -> input to our new classification \"head\"\n",
        "\n",
        "# define our input tensor: (32x32x3) images\n",
        "inputs = Input(shape=(32, 32, 3))\n",
        "\n",
        "# upscale layer to automatically upscale our images to the correct InceptionResNet-V2 input size\n",
        "upscale = Lambda(lambda x: tf.image.resize_with_pad(x,\n",
        "                                                    160,\n",
        "                                                    160,\n",
        "                                                    method=tf.image.ResizeMethod.BILINEAR))(inputs)\n",
        "\n",
        "\n",
        "# load the base model and set the input to \"upscale\"\n",
        "base_model = tf.keras.applications.InceptionResNetV2(include_top=False,\n",
        "                                                     weights='imagenet',\n",
        "                                                     input_tensor=upscale,\n",
        "                                                     input_shape=(160,160,3),\n",
        "                                                     pooling='max')\n",
        "\n",
        "\n",
        "# 2) We can choose to enable or disable training of the base model, e.g. only train our new top layers or the whole model\n",
        "base_model.trainable = False\n",
        "\n",
        "# 3) Add our custom top layers to classify CIFAR-10\n",
        "out = base_model.output # we build our new layers at the end of the base model's output\n",
        "out = Flatten()(out)\n",
        "out = BatchNormalization()(out)\n",
        "out = Dense(256, activation='relu')(out)\n",
        "out = Dropout(0.3)(out)\n",
        "out = BatchNormalization()(out)\n",
        "out = Dense(128, activation='relu')(out)\n",
        "out = Dropout(0.3)(out)\n",
        "out = BatchNormalization()(out)\n",
        "out = Dense(64, activation='relu')(out)\n",
        "out = Dropout(0.3)(out)\n",
        "\n",
        "# 10 output neurons, 1 for every CIFAR-10 class\n",
        "out = Dense(10, activation='softmax')(out)\n",
        "\n",
        "\n",
        "# 4) Define the new model\n",
        "modelFineTune = tf.keras.models.Model(inputs=inputs, outputs=out)\n",
        "\n",
        "print(modelFineTune.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGALXFooUBtT"
      },
      "source": [
        "### Preprocess the training and test data (**PROVIDED**)\n",
        "\n",
        "Every pre-trained network in Keras comes with its own preprocessing function that needs to be applied to every training and test image. This preprocessing is the same that has been used to train the initial network on ImageNet. \n",
        "\n",
        "**From now on, we will need to use the preprocessed datasets for training and testing.**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtP-bsJkUZIU"
      },
      "source": [
        "# load the data again, since we have applied a different normalization in our first Excercise\n",
        "(trainSamples, _trainLabels), (testSamples, _testLabels) = cifar10.load_data()\n",
        "\n",
        "# convert a class vector (integers) to binary class matrix.\n",
        "trainLabels  = to_categorical(_trainLabels)\n",
        "testLabels   = to_categorical(_testLabels)\n",
        "\n",
        "# preprocess training and test samples\n",
        "trainSamplesPP = tf.keras.applications.inception_resnet_v2.preprocess_input(np.copy(trainSamples))\n",
        "testSamplesPP  = tf.keras.applications.inception_resnet_v2.preprocess_input(np.copy(testSamples))\n",
        "\n",
        "# class names\n",
        "# text representation of class labels\n",
        "classNames = ['airplane', 'automobile', 'bird', \\\n",
        "               'cat', 'deer', 'dog', \\\n",
        "               'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9NjvIbYLvdN"
      },
      "source": [
        "### CNN Training (top layers only) (**add your code here**)\n",
        "\n",
        "Train the model using your best optimizer from Exercise 1 and the same loss, metrics and hyper parameters as before, except for the ```learning_rate``` which should be decreased to 1e-4. Limit the maximum number of epochs to 10 by setting ```epochs=10```. Evaluate the model's accuracy on the test set. \n",
        "\n",
        "**Depending on the GPU that we are being assigned, one epoch can take up to 5 minutes!**\n",
        "\n",
        "We can provide [ModelCheckpoint](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint) as additional callback to ```model.fit()``` to save our model after every epoch. This comes in very handy when training times increase. And, we can always continue training by loading the saved model and run ```model.fit()``` again. \n",
        "\n",
        "**Note, that only our new layers are trained! See the number of trainable vs. non-trainable parameters in the output of ```model.summary()```**. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcMMI_JiMgEn"
      },
      "source": [
        "# Create a callback that saves the model's weights after every epoch\n",
        "checkpointPath = \"/content/drive/My Drive/cifar-10-training_inception-resnet-v2/myAwesomeCNN.ckpt\"\n",
        "checkPoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpointPath,\n",
        "                                                save_weights_only=True,\n",
        "                                                verbose=1)\n",
        "\n",
        "# Crate an early stopping callback\n",
        "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "\n",
        "# Compile the new CNN model\n",
        "modelFineTune.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "# Train the new CNN model (make sure to use both callbacks defined above !!)\n",
        "history = modelFineTune.fit(x=trainSamplesPP, y=trainLabels, batch_size=64, epochs=10, verbose=1, callbacks=[earlyStopping, checkPoint], validation_data=(testSamplesPP, testLabels))\n",
        "\n",
        "# Evaluate the accuracy\n",
        "_, acc = modelFineTune.evaluate(testSamplesPP, testLabels, verbose=1)\n",
        "print(\"Accuracy = {}\".format(acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePdlK-GmQi3I"
      },
      "source": [
        "### Visualize the performance (**PROVIDED**)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU-djqGWdR0f"
      },
      "source": [
        "# load the model from the saved checkpoint\n",
        "modelFineTune.load_weights(tf.train.latest_checkpoint(os.path.dirname(checkpointPath)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfNRjuiDQol0"
      },
      "source": [
        "visualizePredictions(modelFineTune, testSamplesPP, testSamples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQQKCQTaQz4Q"
      },
      "source": [
        "# for external images, we also need to apply the Inception-ResNet-V2 preprocessing\n",
        "\n",
        "def myPredictInceptionResNet(model, image):\n",
        "\n",
        "  # resize image to model dimensions\n",
        "  resizedImage = cv2.resize(image, (32,32))\n",
        "\n",
        "  # expand dimensions (i.e. build a tensor from a single image)\n",
        "  x=np.expand_dims(resizedImage, axis=0)\n",
        "  \n",
        "  # apply preprocessing\n",
        "  x=tf.keras.applications.inception_resnet_v2.preprocess_input(x)\n",
        "  # and predict \n",
        "  predictedClasses = model.predict(x)\n",
        "  return predictedClasses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_yu0yV9V5di"
      },
      "source": [
        "visualizePredictionsExtImages(modelFineTune, myPredictInceptionResNet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCJqoCTeRiRT"
      },
      "source": [
        "### CNN Training (full CNN) (**add your code here**)\n",
        "\n",
        "In a final experiment, train the full CNN from top to bottom using the same parameters as before.\n",
        "\n",
        "**Depending on the GPU that we are being assigned, one epoch can take up to 17 minutes!**\n",
        "\n",
        "**How does the performance differ?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcGfyv88S04a"
      },
      "source": [
        "# Define a fully trainable model\n",
        "base_model.trainable = True\n",
        "\n",
        "# Replicate the CNN architecture from above and use 'modelFineTuneFull' as a variable for this CNN model. \n",
        "out = base_model.output \n",
        "out = Flatten()(out)\n",
        "out = BatchNormalization()(out)\n",
        "out = Dense(256, activation='relu')(out)\n",
        "out = Dropout(0.3)(out)\n",
        "out = BatchNormalization()(out)\n",
        "out = Dense(128, activation='relu')(out)\n",
        "out = Dropout(0.3)(out)\n",
        "out = BatchNormalization()(out)\n",
        "out = Dense(64, activation='relu')(out)\n",
        "out = Dropout(0.3)(out)\n",
        "\n",
        "out = Dense(10, activation='softmax')(out)\n",
        "\n",
        "modelFineTuneFull = tf.keras.models.Model(inputs=inputs, outputs=out)\n",
        "\n",
        "# Compile the new CNN model\n",
        "modelFineTune.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "# Train the new CNN model (make sure to use both callbacks defined above !!)\n",
        "history = modelFineTune.fit(x=trainSamplesPP, y=trainLabels, batch_size=64, epochs=10, verbose=1, callbacks=[earlyStopping, checkPoint], validation_data=(testSamplesPP, testLabels))\n",
        "\n",
        "# Evaluate the accuracy\n",
        "_, acc = modelFineTune.evaluate(testSamplesPP, testLabels, verbose=1)\n",
        "print(\"Accuracy = {}\".format(acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCegxedXS_07"
      },
      "source": [
        "### Visualize the performance (**PROVIDED**)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz4CT63ode75"
      },
      "source": [
        "# load the model from the saved checkpoint\n",
        "modelFineTuneFull.load_weights(tf.train.latest_checkpoint(os.path.dirname(checkpointPath)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ6noAAeTBS-"
      },
      "source": [
        "visualizePredictions(modelFineTuneFull, testSamplesPP, testSamples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUC-LkisTEIu"
      },
      "source": [
        "visualizePredictionsExtImages(modelFineTuneFull, myPredictInceptionResNet)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}